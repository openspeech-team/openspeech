

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <title>Transformer Transducer Model &mdash; Openspeech v0.3.0 documentation</title>



  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />










  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->


      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>

    <script type="text/javascript" src="../_static/js/theme.js"></script>


    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="AISHELL" href="../corpus/AISHELL-1.html" />
    <link rel="prev" title="Transformer Language Model" href="Transformer LM.html" />
</head>

<body class="wy-body-for-nav">


  <div class="wy-grid-for-nav">

    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >



            <a href="../index.html" class="icon icon-home"> Openspeech



          </a>







<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div>


        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">






              <p class="caption"><span class="caption-text">GETTING STARTED</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notes/intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/hydra_configs.html">Openspeech’s Hydra configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/configs.html">Openspeech’s configurations</a></li>
</ul>
<p class="caption"><span class="caption-text">OPENSPEECH MODELS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../models/Openspeech Model.html">Openspeech Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/Openspeech CTC Model.html">Openspeech CTC Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/Openspeech Encoder Decoder Model.html">Openspeech Encoder Decoder Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/Openspeech Transducer Model.html">Openspeech Transducer Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/Openspeech Language Model.html">Openspeech Language Model</a></li>
</ul>
<p class="caption"><span class="caption-text">MODEL ARCHITECTURES</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Conformer.html">Conformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="ContextNet.html">ContextNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="DeepSpeech2.html">DeepSpeech2</a></li>
<li class="toctree-l1"><a class="reference internal" href="Jasper.html">Jasper</a></li>
<li class="toctree-l1"><a class="reference internal" href="Listen Attend Spell.html">Listen Attend Spell Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="LSTM LM.html">LSTM Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="QuartzNet.html">QuartzNet Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="RNN Transducer.html">RNN Transducer Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Transformer.html">Transformer Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Transformer LM.html">Transformer Language Model</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Transformer Transducer Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">Transformer Transducer Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-openspeech.models.transformer_transducer.configurations">Transformer Transducer Configuration</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">CORPUS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../corpus/AISHELL-1.html">AISHELL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../corpus/KsponSpeech.html">KsponSpeech</a></li>
<li class="toctree-l1"><a class="reference internal" href="../corpus/LibriSpeech.html">LibriSpeech</a></li>
</ul>
<p class="caption"><span class="caption-text">LIBRARY REFERENCE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules/Callback.html">Callback</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/Criterion.html">Criterion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/Data Augment.html">Data Augment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/Feature Transform.html">Feature Transform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/Datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/Data Loaders.html">Data Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/Decoders.html">Decoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/Encoders.html">Encoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/Modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/Optim.html">Optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/Search.html">Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/Tokenizers.html">Tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/Metric.html">Metric</a></li>
</ul>



        </div>

      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">


      <nav class="wy-nav-top" aria-label="top navigation">

          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Openspeech</a>

      </nav>


      <div class="wy-nav-content">

        <div class="rst-content">



















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">

      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>

      <li>Transformer Transducer Model</li>


      <li class="wy-breadcrumbs-aside">


            <a href="../_sources/architectures/Transformer Transducer.rst.txt" rel="nofollow"> View page source</a>


      </li>

  </ul>


  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">

  <div class="section" id="transformer-transducer-model">
<h1>Transformer Transducer Model<a class="headerlink" href="#transformer-transducer-model" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id1">
<h2>Transformer Transducer Model<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-openspeech.models.transformer_transducer.model"></span><dl class="py class">
<dt id="openspeech.models.transformer_transducer.model.TransformerTransducerModel">
<em class="property">class </em><code class="sig-prename descclassname">openspeech.models.transformer_transducer.model.</code><code class="sig-name descname">TransformerTransducerModel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">configs</span><span class="p">:</span> <span class="n">omegaconf.dictconfig.DictConfig</span></em>, <em class="sig-param"><span class="n">tokenizer</span><span class="p">:</span> <span class="n"><a class="reference internal" href="../modules/Tokenizers.html#openspeech.tokenizers.tokenizer.Tokenizer" title="openspeech.tokenizers.tokenizer.Tokenizer">openspeech.tokenizers.tokenizer.Tokenizer</a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/openspeech/models/transformer_transducer/model.html#TransformerTransducerModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#openspeech.models.transformer_transducer.model.TransformerTransducerModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Transformer-Transducer is that every layer is identical for both audio and label encoders.
Unlike the basic transformer structure, the audio encoder and label encoder are separate.
So, the alignment is handled by a separate forward-backward process within the RNN-T architecture.
And we replace the LSTM encoders in RNN-T architecture with Transformer encoders.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>configs</strong> (<em>DictConfig</em>) – configuraion set</p></li>
<li><p><strong>tokenizer</strong> (<a class="reference internal" href="../modules/Tokenizers.html#openspeech.tokenizers.tokenizer.Tokenizer" title="openspeech.tokenizers.tokenizer.Tokenizer"><em>Tokenizer</em></a>) – tokenizer is in charge of preparing the inputs for a model.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><p>inputs (torch.FloatTensor): A input sequence passed to encoders. Typically for inputs this will be a padded <cite>FloatTensor</cite> of size <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">seq_length,</span> <span class="pre">dimension)</span></code>.
input_lengths (torch.LongTensor): The length of input tensor. <code class="docutils literal notranslate"><span class="pre">(batch)</span></code></p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Result of model predictions.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>outputs (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)">dict</a>)</p>
</dd>
</dl>
<dl class="py method">
<dt id="openspeech.models.transformer_transducer.model.TransformerTransducerModel.greedy_decode">
<code class="sig-name descname">greedy_decode</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">encoder_outputs</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git2bfbfd8 ))">torch.Tensor</a></span></em>, <em class="sig-param"><span class="n">max_length</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git2bfbfd8 ))">torch.Tensor</a><a class="reference internal" href="../_modules/openspeech/models/transformer_transducer/model.html#TransformerTransducerModel.greedy_decode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#openspeech.models.transformer_transducer.model.TransformerTransducerModel.greedy_decode" title="Permalink to this definition">¶</a></dt>
<dd><p>Decode <cite>encoder_outputs</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder_outputs</strong> (<em>torch.FloatTensor</em>) – A output sequence of encoders. <cite>FloatTensor</cite> of size <code class="docutils literal notranslate"><span class="pre">(seq_length,</span> <span class="pre">dimension)</span></code></p></li>
<li><p><strong>max_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – max decoding time step</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>model’s predictions.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>y_hats (torch.IntTensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="openspeech.models.transformer_transducer.model.TransformerTransducerModel.set_beam_decode">
<code class="sig-name descname">set_beam_decode</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">beam_size</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">3</span></em>, <em class="sig-param"><span class="n">expand_beam</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)">float</a></span> <span class="o">=</span> <span class="default_value">2.3</span></em>, <em class="sig-param"><span class="n">state_beam</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)">float</a></span> <span class="o">=</span> <span class="default_value">4.6</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/openspeech/models/transformer_transducer/model.html#TransformerTransducerModel.set_beam_decode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#openspeech.models.transformer_transducer.model.TransformerTransducerModel.set_beam_decode" title="Permalink to this definition">¶</a></dt>
<dd><p>Setting beam search decode</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-openspeech.models.transformer_transducer.configurations">
<span id="transformer-transducer-configuration"></span><h2>Transformer Transducer Configuration<a class="headerlink" href="#module-openspeech.models.transformer_transducer.configurations" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="openspeech.models.transformer_transducer.configurations.TransformerTransducerConfigs">
<em class="property">class </em><code class="sig-prename descclassname">openspeech.models.transformer_transducer.configurations.</code><code class="sig-name descname">TransformerTransducerConfigs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_name</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)">str</a></span> <span class="o">=</span> <span class="default_value">'transformer_transducer'</span></em>, <em class="sig-param"><span class="n">encoder_dim</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">512</span></em>, <em class="sig-param"><span class="n">d_ff</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">2048</span></em>, <em class="sig-param"><span class="n">num_audio_layers</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">18</span></em>, <em class="sig-param"><span class="n">num_label_layers</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">2</span></em>, <em class="sig-param"><span class="n">num_attention_heads</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">8</span></em>, <em class="sig-param"><span class="n">audio_dropout_p</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)">float</a></span> <span class="o">=</span> <span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">label_dropout_p</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)">float</a></span> <span class="o">=</span> <span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">decoder_hidden_state_dim</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">512</span></em>, <em class="sig-param"><span class="n">decoder_output_dim</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">512</span></em>, <em class="sig-param"><span class="n">conv_kernel_size</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">31</span></em>, <em class="sig-param"><span class="n">max_positional_length</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span> <span class="o">=</span> <span class="default_value">5000</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)">str</a></span> <span class="o">=</span> <span class="default_value">'adam'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/openspeech/models/transformer_transducer/configurations.html#TransformerTransducerConfigs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#openspeech.models.transformer_transducer.configurations.TransformerTransducerConfigs" title="Permalink to this definition">¶</a></dt>
<dd><p>This is the configuration class to store the configuration of
a <code class="xref py py-class docutils literal notranslate"><span class="pre">TransformerTransducer</span></code>.</p>
<p>It is used to initiated an <cite>TransformerTransducer</cite> model.</p>
<p>Configuration objects inherit from :class: <cite>~openspeech.dataclass.configs.OpenspeechDataclass</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Model name (default: transformer_transducer)</p></li>
<li><p><strong>extractor</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – The CNN feature extractor. (default: conv2d_subsample)</p></li>
<li><p><strong>d_model</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Dimension of model. (default: 512)</p></li>
<li><p><strong>d_ff</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Dimension of feed forward network. (default: 2048)</p></li>
<li><p><strong>num_attention_heads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of attention heads. (default: 8)</p></li>
<li><p><strong>num_audio_layers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of audio layers. (default: 18)</p></li>
<li><p><strong>num_label_layers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of label layers. (default: 2)</p></li>
<li><p><strong>audio_dropout_p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The dropout probability of encoder. (default: 0.1)</p></li>
<li><p><strong>label_dropout_p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The dropout probability of decoder. (default: 0.1)</p></li>
<li><p><strong>decoder_hidden_state_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Hidden state dimension of decoder (default: 512)</p></li>
<li><p><strong>decoder_output_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – dimension of model output. (default: 512)</p></li>
<li><p><strong>conv_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Kernel size of convolution layer. (default: 31)</p></li>
<li><p><strong>max_positional_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Max length of positional encoding. (default: 5000)</p></li>
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Optimizer for training. (default: adam)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
</div>


           </div>

          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../corpus/AISHELL-1.html" class="btn btn-neutral float-right" title="AISHELL" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="Transformer LM.html" class="btn btn-neutral float-left" title="Transformer Language Model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Kim, Soohwan and Ha, Sangchun and Cho, Soyoung.

    </p>
  </div>



    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a

    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>

    provided by <a href="https://readthedocs.org">Read the Docs</a>.

</footer>
        </div>
      </div>

    </section>

  </div>


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>






</body>
</html>